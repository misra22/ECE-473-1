{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo68A2ltMkJZ"
   },
   "source": [
    "# ECE 473 Assignment 1\n",
    "\n",
    "## **Submission Instructions**\n",
    "All submissions should be uploaded to Gradescope as a PDF version of your current jupyter notebook (see `uploader.ipynb`). See `uploading-instructions.docx` for more information. NOTE: Other ways of converting to PDF may have missing figures or code and could result in grading penalties. In this assignment you only need to submit sections 3, 4, 5 and 6.\n",
    "\n",
    "Remember:\n",
    "1. **Make sure to select the correct pages for each question on Gradescope.** Failure to do so could result in a 0.\n",
    "2. **Make sure your code and output are visible on the PDF.** (should be true if you use the method explained above.)\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0qw691FVGPi"
   },
   "source": [
    "## 1. Background\n",
    "In this assignment, we are trying to do simple sentiment analysis. Sentiment analysis is the process of detecting positive or negative sentiment in text. It’s often used by businesses to detect sentiment in social data, gauge brand reputation, and understand customers.\n",
    "\n",
    "The dataset we will be using is called [***Stanford Sentiment Treebank***](https://nlp.stanford.edu/sentiment/code.html). This dataset is collected from movie reviews on *Rotten Tomatoes* for over 20k sentences. All reviews later got re-organized as distinct phrases with label as number 0.0 to 1.0. Labels can later be divided in to five intervals [0, 0.2], (0.2, 0.4], (0.4, 0.6], (0.6, 0.8], (0.8, 1.0] which means very negative, negative, neutral, positive, very positive, respectively.\n",
    "\n",
    "The dataset we are using in this assignment is a subset of Stanford Sentiment Treebank and consists of **400 phrases**. Train-test dataset split ratio is 50/50 and for either train or test dataset, half of them are extremely positive reviews (have corresponding range (0.9, 1.0]), and the other half are extremely negative reviews (have corresponding range [0.0, 0.1]). Your job is to construct a simple function that takes a single phrase in and outputs whether this phrase has positive or negative sentiment. You can inspect the training dataset to understand the types of phrases that are used.\n",
    "\n",
    "**The goal of this assignment is to attempt to implement a method from the 1st wave of AI, namely handcrafted knowledge systems. Thus, you will be trying to create a rule-based function for this task based on your prior knowledge and some examples from the training dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuRq9xvxNoX4"
   },
   "source": [
    "## 2. Mounting your google drive on Colab\n",
    "Since colab is running on a remote server on Google, you need to mount your google drive on Colab to serve as a 'local directory' to your coding environment. Luckily, it is as simple as two steps! Try to run this block and follow the instructions that pop out.\n",
    "\n",
    "Note: This part is not necessary if you are using your own Python environment or other remote python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1705082645927,
     "user": {
      "displayName": "Souradip Pal",
      "userId": "00022299520318460014"
     },
     "user_tz": 300
    },
    "id": "pSTudka7I6gH",
    "outputId": "96027f34-d34d-49e8-91eb-155a6f8bd932"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKX2M2NfOvPH"
   },
   "source": [
    "## 3. Load data (10/100 points)\n",
    "Now, we need to load the data from the \"train.txt\" and \"test.txt\" file. Please change the location for **dir_root** in the following code block to where you saved all your files.\n",
    "\n",
    "Train dataset is stored in the \"train.txt\" file which stores 100 positive phrases and 100 negative phrases. Each line in the file is consist of a phrase and the corresponding sentiment positive(1) or negative(-1) followed by a separation mark '|'.\n",
    "\n",
    "Tips: It is helpful and sometimes necessary to have a separate folder for each assignment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "neQW_OYmI_me"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "dir_root = ''\n",
    "#########################        YOUR CODE        #########################\n",
    "#dir_root = '/content/drive/MyDrive/Colab Notebooks/ECE473/Assignment-1'        # change this root directory\n",
    "#########################      END YOUR CODE      #########################                                                                           # for better path controls\n",
    "train_file = os.path.join(dir_root, 'train.txt')                                      # locate the train.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1705082646560,
     "user": {
      "displayName": "Souradip Pal",
      "userId": "00022299520318460014"
     },
     "user_tz": 300
    },
    "id": "B2dxJu94JQ8Z",
    "outputId": "a1a5e42c-797a-4d45-e122-3ff3ecb4a606"
   },
   "outputs": [],
   "source": [
    "# use built-in function \"open\" to read files\n",
    "f = open(train_file, 'r')\n",
    "train_lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "# construct two lists to store phrases and labels seperately\n",
    "train_data, train_label = [], []\n",
    "#### YOUR CODE HERE ####\n",
    "# Populate the train_data and train_label lists by splitting\n",
    "# each line of train.txt by the \"|\" character and adding\n",
    "# the phrase and label (converted to an int) to the lists\n",
    "\n",
    "\n",
    "#### END YOUR CODE ####\n",
    "# preview some data here\n",
    "preview = 10                 # feel free to toggle this number to see more/less data\n",
    "for i in range(preview):\n",
    "    print(f'Phrase \\\"{train_data[i]}\\\" has the sentiment {train_label[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1T1q9wTNm4D"
   },
   "source": [
    "## 4. Manually inspect word frequencies (30/100 points)\n",
    "Now, we need to analyze the data from the \"train.txt\" file. One way to do is to analyze the frequency of individual words in the data based on the occurrence of the word in positive or negative phrases. We can also categorize words as positive or negative based on the number of times that word occurs in positive or negative phrases. You don't need to do any preprocessing of the words like filtering extremely small words e.g. `i`, `it`, `as`, etc. or remove punctuation, stops words, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1705082646705,
     "user": {
      "displayName": "Souradip Pal",
      "userId": "00022299520318460014"
     },
     "user_tz": 300
    },
    "id": "o3ULry4faGic",
    "outputId": "6f8b6e0e-047b-4335-94b7-964cb5431e62"
   },
   "outputs": [],
   "source": [
    "# Create word frequency analysis\n",
    "def word_frequency(data, label):\n",
    "    words = dict()\n",
    "    #### YOUR CODE HERE ####\n",
    "    # Calculate the frequency of each word in the given phrases (`data`) and\n",
    "    #   determine the number of the positive or negative occurences based on the\n",
    "    #   corresponding labels (`label`)\n",
    "    # The `words` dictionary should contain each word as key and the total, positive and\n",
    "    #   negative counts as value. e.g. words['best'] = {'total': 2, 'pos': 1, 'neg': 1}\n",
    "    # All words should be converted to lower case\n",
    "\n",
    "    #### END YOUR CODE ####\n",
    "    return words\n",
    "\n",
    "words =  word_frequency(train_data, train_label)\n",
    "print('total' in words['best'] and 'pos' in words['best'] and 'neg' in words['best']) # True\n",
    "print(words['best']) # {'total': 12, 'pos': 12, 'neg': 0}\n",
    "\n",
    "print('Top 20 positive words (largest ratio in positive posts)')\n",
    "display(sorted(words.items(), key=lambda x: (x[1]['pos']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n",
    "# [('best', {'total': 12, 'pos': 12, 'neg': 0}),\n",
    "# ('brilliant', {'total': 6, 'pos': 6, 'neg': 0}), ...\n",
    "print('Top 20 negative words (largest ratio in negative posts)')\n",
    "display(sorted(words.items(), key=lambda x: (x[1]['neg']/x[1]['total'], x[1]['total']), reverse=True)[:20])\n",
    "# [('i', {'total': 11, 'pos': 0, 'neg': 11}),\n",
    "#  ('bad', {'total': 10, 'pos': 0, 'neg': 10}), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH3n1eHKhGm6"
   },
   "source": [
    "## 5. Handcrafted / Hardcoded Classifier (25/100 points)\n",
    "Please fill in code in the provided skeleton for the function `sentiment_analysis_model` which has the following structure:\n",
    "* Input: a single string `phrase`\n",
    "* output: an integer `-1` or `1`. `-1` stands for negative sentiment and `1` stands for positive sentiment\n",
    "\n",
    "Importantly, this is meant to be like the *first wave of AI* with **hardcoded / handcrafted rules**. You should not use any ML or AI package for this assignment. You can manually look at the train dataset to understand words or phrases that might be positive or negative and can then hardcode these words and possibly weights into your classifier.\n",
    "\n",
    "Notes:\n",
    "1. Try to constrain your code for `sentiment_analysis_model` to within **50 lines without importing any additional packages** (i.e, this assignment does not require you to perform any complicated model analysis)\n",
    "2. You can view all the training phrases by opening file *'train.txt'* in the provided zip file.\n",
    "3. Throughout the design of your algorithm, **you should only have access to the train dataset** stored in \"train.txt\". The test dataset stored in 'test.npy' should only be used in the next evaluation section. You can think that train dataset is what we would actually have to learn from (like course materials and lectures) while test is new data that simulates real-world posts (where we wouldn’t usually know the true labels).\n",
    "4. Try to get the train accuracy to be higher than 55% to receive full credit!\n",
    "\n",
    "You might find the following hints helpful (not required to use them):\n",
    "1. Inspect the frequency table for the words in the training dataset based on your outputs above.\n",
    "2. You might want to use the Python keyword `in` for seeing if one string is in another.\n",
    "3. You might want to use the `lower()` or `upper()` string functions.\n",
    "4. Manually define (i.e., hand-craft) your own rules/criteria for good vs. bad review (e.g. you may want to consider words that are usually good or bad). You can also use the list of positive and negative words that you determined in the previous section for defining the criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1705082646706,
     "user": {
      "displayName": "Souradip Pal",
      "userId": "00022299520318460014"
     },
     "user_tz": 300
    },
    "id": "TNCrqyudK5NU",
    "outputId": "7c02943c-60e9-42e9-c140-04c352e4ee94"
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis_model(phrase):\n",
    "    \"\"\"\n",
    "    sentiment_analysis function determines whether a phrase is positive (1) or negative (-1).\n",
    "\n",
    "    :param1(string) phrase: a single phrase in the format of string\n",
    "    :return(int)          : 1 if the phrase is postive or -1 if the phrase is negative\n",
    "    \"\"\"\n",
    "\n",
    "    #########################        YOUR CODE        #########################\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #########################      END YOUR CODE      #########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrix (15/100 points) \n",
    "\n",
    "A confusion matrix is a table used to describe the performance of a classification model. For binary classification (in this case, positive and negative sentiment), it consists of four categories:\n",
    "\n",
    "- **True Positive (TP)**: Correctly predicted positive sentiment\n",
    "- **True Negative (TN)**: Correctly predicted negative sentiment\n",
    "- **False Positive (FP)**: Incorrectly predicted positive sentiment (actual was negative)\n",
    "- **False Negative (FN)**: Incorrectly predicted negative sentiment (actual was positive)\n",
    "\n",
    "The accuracy is calculated as:\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}} $$\n",
    "\n",
    "\n",
    "### Example: Confusion Matrix Calculation\n",
    "\n",
    "Let's consider a scenario with 5 predictions and 5 actual labels:\n",
    "\n",
    "```python\n",
    "predictions = [1, -1, 1, -1, 1]\n",
    "actual_labels = [1, -1, -1, 1, 1]\n",
    "```\n",
    "\n",
    "Here's how we would calculate the confusion matrix:\n",
    "\n",
    "1. (1, 1): TP (correct positive)\n",
    "2. (-1, -1): TN (correct negative)\n",
    "3. (1, -1): FP (predicted positive, actually negative)\n",
    "4. (-1, 1): FN (predicted negative, actually positive)\n",
    "5. (1, 1): TP (correct positive)\n",
    "\n",
    "Resulting confusion matrix:\n",
    "\n",
    "| Category | Count |\n",
    "|----------|-------|\n",
    "| TP       | 2     |\n",
    "| TN       | 1     |\n",
    "| FP       | 1     |\n",
    "| FN       | 1     |\n",
    "\n",
    "Accuracy calculation:\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}} = \\frac{2 + 1}{2 + 1 + 1 + 1} = \\frac{3}{5} = 0.6 $$\n",
    "\n",
    "So, for this example, the accuracy would be 60%.\n",
    "\n",
    "\n",
    "Now, fill in the function `evaluate` to calculate the confusion matrix and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(func, data, label):\n",
    "    # Initialize confusion matrix\n",
    "    confusion_matrix = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "\n",
    "    #########################       YOUR CODE      #########################\n",
    "    # Evaluate the accuracy of the model (passed as the function `func`)\n",
    "    #   on the given phrases (`data`) and corresponding labels (`label`)\n",
    "    # For each phrase in `data`, compute the model's prediction for the phrase\n",
    "    #   and then determine if the prediction is equal to the true corresponding\n",
    "    #   label from `label`.\n",
    "    # Count the number of TP, TN, FP, and FN to get the accuracy\n",
    "    \n",
    "    \n",
    "\n",
    "    #########################   END YOUR CODE      #########################\n",
    "    return train_acc, confusion_matrix\n",
    "\n",
    "train_acc, confusion_matrix = evaluate(sentiment_analysis_model, train_data, train_label)\n",
    "print(f\"Confusion Matrix: {confusion_matrix}\")\n",
    "print(f\"Accuracy: (TP + TN) / (TP + TN + FP + FN) = \"\n",
    "      f\"({confusion_matrix['TP']} + {confusion_matrix['TN']}) / \"\n",
    "      f\"({confusion_matrix['TP']} + {confusion_matrix['TN']} + \"\n",
    "      f\"{confusion_matrix['FP']} + {confusion_matrix['FN']}) * 100% = \"\n",
    "      f\"{train_acc * 100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AadzsP3uRWib"
   },
   "source": [
    "## 7. Evaluate (20/100 points)\n",
    "You may already notice that there is an extra evaluation function in the above coding block which helps calculate the accuracy for your algorithm in the training dataset. The metric that we used to evaluate is straightforward:    \n",
    "$$Accuracy = \\frac{\\# \\text{ of correct prediction}}{\\# \\text{ of total cases}}$$\n",
    "Now, let's test the performances of your algorithm in test dataset!\n",
    "Try to get the **test accuracy** to be higher than 55% to receive **full credit**!\n",
    "\n",
    "Note: You should not have the accuracy to be lower than 50%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1705082647522,
     "user": {
      "displayName": "Souradip Pal",
      "userId": "00022299520318460014"
     },
     "user_tz": 300
    },
    "id": "JaoWgyj2K1TR",
    "outputId": "51433da7-6a99-452a-b8e8-82b75dc3c55a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(dir_root)\n",
    "from top_classified_file import super_secret_function\n",
    "\n",
    "test_dir = os.path.join(dir_root, 'test.npy')\n",
    "test_acc = super_secret_function(test_dir, sentiment_analysis_model)\n",
    "\n",
    "print(f\"Your method has the test accuracy of {test_acc*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdSf3f-uS5jt"
   },
   "source": [
    "## 8. Did you notice something interesting? (Optional)\n",
    "1. During your design, does training accuracy always a little bit higher than test accuracy? Why?\n",
    "2. Does the sentiment analysis task a little bit harder than you expected?\n",
    "3. ... something else you would like to talk about"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
